<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haochen TAN</title>

    <meta name="author" content="Haochen TAN">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Haochen TAN
                </p>
                <p>I'm a PhD student in the Computer Science Department of <a href="https://www.cs.cityu.edu.hk/">City University of Hong Kong</a> in HKSAR. My PhD supervisor is <a href="https://sites.google.com/site/aisquaredlab/">Prof. Linqi Song</a>. Currently I am a research intern at <a href="https://www.noahlab.com.hk/#/home">Noah's Ark Lab</a> under the supervision of <a href="https://cartus.github.io/">Zhijiang Guo</a>.
                </p>
                <p>
                  At CityU, I work on the sentence comprehension, long sequence compression and evaluation. Before joined Prof. Song's team, I was a research assistant under the supversion of <a href="https://scholar.google.com.hk/citations?user=J4aqOWUAAAAJ&hl=en">Dr. Bernard Chiu</a>. In my undergraduate years, I was advised by <a href="https://faculty.uestc.edu.cn/fancong/en/jsxx/194733/jsxx/jsxx.htm">Cong Fan</a> at <a href="https://www.uestc.edu.cn/">UESTC</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:haochetan2-c@my.city.edu.hk">Email</a> &nbsp;/&nbsp;
                  <a href="data/TAN_Haochen_CityU.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=LRACzBoAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Namco0816/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/haochen_crop.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/haochen_crop.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in natural language processing, deep learning, generative AI. Most of my research is about sentence representation, lenghty sequence compression, long-form generation and evaluation. 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/proxyqa.png" alt="prl" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2401.15042.pdf">
                  <span class="papertitle">PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models</span>
                </a>
                <br>
                <strong>Haochen Tan</strong>, <a href="https://cartus.github.io/">Zhijiang Guo</a>, Zhan Shi, Lu Xu, Zhili Liu, Yunlong Feng, Xiaoguang Li, Yasheng Wang, Lifeng Shang, Qun Liu, Linqi Song</a>
                <br>
                <em>Under Review</em>, 2024
                <br>
                <p>In this paper, we propose PROXYQA, an innovative framework dedicated to the assessment of long-text generation. PROXYQA comprises in-depth human-curated metaquestions spanning various domains, each accompanied by specific proxy-questions with pre-annotated answers.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/rbs.png" alt="blind-date" width="200" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2305.07988">
                  <span class="papertitle">Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts</span>
                </a>
                <br>
                <strong>Haochen Tan</strong>, <a href="https://hahahawu.com/">Han Wu</a>, Wei Shao, Xinyun Zhang, Mingjie Zhan, Zhaohui Hou, Ding Liang, Linqi Song</a>
                <br>
                <em>EMNLP 2023</em>
                <p>we propose a two-step framework, Reconstruct before Summarize (RbS), for effective and efficient meeting summarization. RbS first leverages a self-supervised paradigm to annotate essential contents by reconstructing the meeting transcripts. Secondly, we propose a relative positional bucketing (RPB) algorithm to equip (conventional) summarization models to generate the summary.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/iclr_hanwu.png" alt="clean-usnob" width="200" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2205.14583">
                  <span class="papertitle">Learning Locality and Isotropy in Dialogue Modeling</span>
                </a>
                <br>
                Han Wu, <strong>Haochen Tan</strong>, Mingjie Zhan, Gangming Zhao, Shaoqing Lu, Ding Liang, Linqi Song</a>
                <br>
                <em>ICLR 2023</em>
                <p>we identify two properties in dialogue modeling, i.e., locality and isotropy, and present a simple method for dialogue representation calibration, namely SimDRC, to build isotropic and conversational feature spaces. Experimental results show that our approach significantly outperforms the current state-of-the-art models on three dialogue tasks across the automatic and human evaluation metrics.</p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/rbs.png" alt="blind-date" width="200" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2305.07988">
                  <span class="papertitle">Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts</span>
                </a>
                <br>
                <strong>Haochen Tan</strong>, <a href="https://hahahawu.com/">Han Wu</a>, Wei Shao, Xinyun Zhang, Mingjie Zhan, Zhaohui Hou, Ding Liang, Linqi Song</a>
                <br>
                <em>EMNLP 2023</em>
                <p>we propose a two-step framework, Reconstruct before Summarize (RbS), for effective and efficient meeting summarization. RbS first leverages a self-supervised paradigm to annotate essential contents by reconstructing the meeting transcripts. Secondly, we propose a relative positional bucketing (RPB) algorithm to equip (conventional) summarization models to generate the summary.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/zero_shot.png" alt="blind-date" width="200" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2204.04914">
                  <span class="papertitle">Zero-shot Cross-lingual Conversational Semantic Role Labeling</span>
                </a>
                <br>
                Han Wu, <strong>Haochen Tan</strong>, Kun Xu, Shuqi Liu, Lianwei Wu, Linqi Song</a>
                <br>
                <em>Findings of NAACL, 2022</em>
                <p>To avoid expensive data collection and error-propagation of translation-based methods, we present a simple but effective approach to perform zero-shot cross-lingual CSRL. Our model implicitly learns language-agnostic, conversational structure-aware and semantically rich representations with the hierarchical encoders and elaborately designed pre-training objectives. </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/128_tok.png" alt="blind-date" width="200" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://aclanthology.org/2022.findings-acl.22/">
                  <span class="papertitle">A Sentence is Worth 128 Pseudo Tokens: A Semantic-Aware Contrastive Learning Framework for Sentence Embeddings</span>
                </a>
                <br>
                <strong>Haochen Tan</strong>, Wei Shao, Han Wu, Ke Yang, Linqi Song</a>
                <br>
                <em>Findings of ACL 2022</em>
                <p>In this paper, we propose a semantic-aware contrastive learning framework for sentence embeddings, termed Pseudo-Token BERT (PT-BERT), which is able to explore the pseudo-token space (i.e., latent semantic space) representation of a sentence while eliminating the impact of superficial features such as sentence length and syntax. </p>
              </td>
            </tr>



          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/acl-logo.svg"></td>
              <td width="75%" valign="center">
                <a href="https://2024.aclweb.org/">Reviewer, ACL 2024</a>
                <br>
                <a href="https://2023.emnlp.org/">Reviewer, EMNLP 2023</a>
                <br>
                <a href="https://2023.aclweb.org/">Reviewer, ACL 2023</a>
                <br>
                <a href="https://2022.emnlp.org/">Reviewer, EMNLP 2022</a>
              </td>
            </tr>
           
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Updated at July 2023, Thanks <a href="https://github.com/leonidk/new_website">Jon Barron</a> for this amazing template.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
